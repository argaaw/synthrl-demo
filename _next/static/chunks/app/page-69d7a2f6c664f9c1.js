(self.webpackChunk_N_E=self.webpackChunk_N_E||[]).push([[974],{1057:(e,t,a)=>{"use strict";a.r(t),a.d(t,{default:()=>i});var n=a(5155),s=a(2115);function i(){let[e,t]=(0,s.useState)(null);return(0,n.jsxs)("main",{className:"min-h-screen w-full bg-gradient-to-tr from-[#f1f5fa] via-[#e3eaf6] to-[#cfd8e9] flex flex-col items-center p-0",children:[(0,n.jsx)("header",{className:"w-full",children:(0,n.jsxs)("div",{className:" w-full bg-gradient-to-r from-[#dbeafe] via-[#c7d2fe] to-[#e0e7ff] shadow-md py-14 px-4 md:px-0 flex flex-col items-center ",children:[(0,n.jsx)("h1",{className:"text-5xl md:text-6xl font-extrabold text-gray-900 tracking-tight mb-4 text-center drop-shadow-sm",children:"SynthRL"}),(0,n.jsx)("h2",{className:"text-2xl md:text-3xl font-light text-gray-700 text-center max-w-3xl drop-shadow-sm",children:"Cross-domain Synthesizer Sound Matching via Reinforcement Learning"})]})}),(0,n.jsxs)("div",{className:"w-full flex flex-col items-center pt-8 pb-2",children:[(0,n.jsx)("div",{className:"text-lg font-semibold text-gray-700 tracking-tight",children:"Wonchul Shin and Kyogu Lee"}),(0,n.jsx)("div",{className:"text-base text-gray-500 font-light mt-0.5 mb-3",children:"Music and Audio Research Group (MARG), Seoul National University"})]}),(0,n.jsx)("section",{className:"w-full flex justify-center mb-10",children:(0,n.jsxs)("div",{className:"max-w-2xl px-6",children:[(0,n.jsx)("div",{className:"uppercase text-xs font-semibold text-gray-400 mb-2 tracking-widest",children:"Abstract"}),(0,n.jsx)("div",{className:"text-[1rem] leading-relaxed text-gray-700",children:"\nGeneralization of synthesizer sound matching to external instrument sounds is highly challenging due to the non-differentiability of sound synthesis process which prohibits the use of out-of-domain sounds for training with synthesis parameter loss. We propose SynthRL, a novel reinforcement learning (RL)-based approach for cross-domain synthesizer sound matching. By incorporating sound similarity into the reward function, SynthRL effectively optimizes synthesis parameters without ground-truth labels, allowing fine-tuning on out-of-domain sounds. Furthermore, we introduce a transformer-based model architecture and reward-based prioritized experience replay to enhance RL training efficiency, considering the unique characteristics of the task. Experimental results demonstrate that SynthRL outperforms state-of-the-art methods on both in-domain and out-of-domain tasks. Further experimental analysis validates the effectiveness of our reward design, showing a strong correlation with human perception of sound similarity.\n".trim()})]})}),(0,n.jsx)("section",{className:"max-w-3xl w-full space-y-7 mt-8",children:[{name:"샘플 1",filename:"0_GroundTruth.wav"},{name:"샘플 2",filename:"0_SynthRL-i.wav"},{name:"샘플 3",filename:"0_SynthRL-p.wav"}].map((a,s)=>(0,n.jsxs)("div",{className:"border border-gray-200 p-6 rounded-2xl shadow-md hover:shadow-lg transition-all duration-200 bg-white/90 backdrop-blur-lg",children:[(0,n.jsx)("p",{className:"font-semibold mb-3 text-gray-700",children:a.name}),(0,n.jsx)("audio",{controls:!0,src:"/audio/".concat(a.filename),className:"w-full rounded-lg",onPlay:()=>t(a.filename)}),e===a.filename&&(0,n.jsx)("p",{className:"text-sm text-blue-600 mt-2 font-medium animate-pulse",children:"▶ 재생 중"})]},s))}),(0,n.jsxs)("footer",{className:"w-full mt-24 mb-8 text-center text-gray-400 text-sm",children:["\xa9 ",new Date().getFullYear()," SynthRL Demo"]})]})}},5714:(e,t,a)=>{Promise.resolve().then(a.bind(a,1057))}},e=>{var t=t=>e(e.s=t);e.O(0,[441,684,358],()=>t(5714)),_N_E=e.O()}]);